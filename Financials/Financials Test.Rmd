---
title: "Train and evaluate models with tidymodels"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5)
```

```{r}
# Load libraries
library(tidyverse)
library(tidyquant)
library(timetk)
library(tibbletime)
library(scales)
library(highcharter)
library(broom)
library(PerformanceAnalytics)
library(polite)
library(finreportr)
library(tidymodels)
```

```{r}
# Load data
df <- read_csv("2022-02-12-WatchListScanner.csv")
```

## Explore data

Exploratory data analysis (EDA) is an [important part of the modeling process](https://www.tmwr.org/software-modeling.html#model-phases).

```{r}
df %>%
  skimr::skim()
```

```{r}
df %>%
  arrange(`Free Cash Flow Per Share - Current (Annual)`, EPS, Last)
```

```{r}
AnnualReports("GOOG")
```

```{r}
library(tidyverse)
library(httr)
library(rvest)
library(jsonlite)
library(polite)
```

```{r}
info <- getFilingInfo('United Technologies', c(2005, 2006), 
                       quarter = c(1,2), form.type = c('8-K','10-K'), "eugenezh@usc.edu")
```

```{r}
output <- getFilings(cik.no = c(1000180, 38079), c('10-K','10-Q'), 
                     2006, quarter = c(1, 2, 3), downl.permit = "n", "eugenezh@usc.edu")

```

```{r}
senti.df <- getSentiment(cik.no = c('1000180', '38079'), 
                         form.type = '10-K', filing.year = 2006, "eugenezh@usc.edu") 
```


## Build models

Let's consider how to [spend our data budget](https://www.tmwr.org/splitting.html):

- create training and testing sets
- create resampling folds from the *training* set

```{r}
set.seed(123)
penguin_split <- initial_split(penguins, strata = sex)
penguin_train <- training(penguin_split)
penguin_test <- testing(penguin_split)

set.seed(234)
penguin_folds <- vfold_cv(penguin_train, strata = sex)
penguin_folds
```

Let's create a [**model specification**](https://www.tmwr.org/models.html) for each model we want to try:

```{r}
glm_spec <-
  logistic_reg() %>%
  set_engine("glm")

ranger_spec <-
  rand_forest(trees = 1e3) %>%
  set_engine("ranger") %>%
  set_mode("classification")
```

To set up your modeling code, consider using the [parsnip addin](https://parsnip.tidymodels.org/reference/parsnip_addin.html) or the [usemodels](https://usemodels.tidymodels.org/) package.

Now let's build a [**model workflow**](https://www.tmwr.org/workflows.html) combining each model specification with a data preprocessor:

```{r}
penguin_formula <- sex ~ .

glm_wf    <- workflow(penguin_formula, glm_spec)
ranger_wf <- workflow(penguin_formula, ranger_spec)
```

If your feature engineering needs are more complex than provided by a formula like `sex ~ .`, use a [recipe](https://www.tidymodels.org/start/recipes/). [Read more about feature engineering with recipes](https://www.tmwr.org/recipes.html) to learn how they work.


## Evaluate models

These models have no tuning parameters so we can evaluate them as they are. [Learn about tuning hyperparameters here.](https://www.tidymodels.org/start/tuning/)

```{r}
contrl_preds <- control_resamples(save_pred = TRUE)

glm_rs <- fit_resamples(
  glm_wf,
  resamples = penguin_folds,
  control = contrl_preds
)

ranger_rs <- fit_resamples(
  ranger_wf,
  resamples = penguin_folds,
  control = contrl_preds
)
```

How did these two models compare?

```{r}
collect_metrics(glm_rs)
collect_metrics(ranger_rs)
```

We can visualize these results using an ROC curve (or a confusion matrix via `conf_mat()`):

```{r}
bind_rows(
  collect_predictions(glm_rs) %>%
    mutate(mod = "glm"),
  collect_predictions(ranger_rs) %>%
    mutate(mod = "ranger")
) %>%
  group_by(mod) %>%
  roc_curve(sex, .pred_female) %>%
  autoplot()
```

These models perform very similarly, so perhaps we would choose the simpler, linear model. The function `last_fit()` *fits* one final time on the training data and *evaluates* on the testing data. This is the first time we have used the testing data.

```{r}
final_fitted <- last_fit(glm_wf, penguin_split)
collect_metrics(final_fitted)  ## metrics evaluated on the *testing* data
```

This object contains a fitted workflow that we can use for prediction.

```{r}
final_wf <- extract_workflow(final_fitted)
predict(final_wf, penguin_test[55,])
```

You can save this fitted `final_wf` object to use later with new data, for example with `readr::write_rds()`.
